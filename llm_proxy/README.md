# ⚡️ llm_proxy – Lambda Backend

`lambda_function.py` is the AWS Lambda-compatible Python script powering Ask Buzz’s backend. It receives event queries from the frontend, loads event data from `feed.data` (generated by the scraper), uses the OpenAI API to generate summaries and answers, and returns structured JSON responses to the web client. This enables intelligent search and summaries of Georgia Tech calendar events.

---

## ⚙️ Setup
1. **Install dependencies** (from the `llm_proxy` directory):
   ```bash
   pip install openai feedparser beautifulsoup4
   ```
2. **Set your OpenAI API key** as an environment variable, or securely in your deployment.

---

## 🚀 Deploy to AWS Lambda
- Zip `lambda_function.py` and all dependencies
- Deploy via AWS Console or CLI
- Set required environment variables (API keys)

---

## 🧪 Usage Example
The Lambda expects a GET request with a `query` parameter. It reads `feed.data` and returns a structured JSON response.

---

## 🔐 Environment Variables
- `OPENAI_API_KEY`: Your OpenAI API key (**required**)

---

## 🛟 Troubleshooting
- Ensure `feed.data` exists and is up to date (run the scraper if needed)
- Check AWS Lambda logs for errors
- Make sure all dependencies are included in your deployment package

---

For more, see the main project [README](../README.md).
